{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f424243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a750ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dementia Prediction Dataset.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc021634",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83e3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.DEMENTED.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f389471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- A1 Demographics ---\n",
    "a1_cols = [\n",
    "    \"NACCAGE\", \"SEX\", \"EDUC\", \"RACE\", \"RACESEC\", \"RACETER\",\n",
    "    \"PRIMLANG\", \"MARISTAT\", \"RESIDENC\", \"NACCLIVS\",\n",
    "    \"INDEPEND\", \"HANDED\", \"NACCREFR\", \"NACCREAS\",\n",
    "]\n",
    "\n",
    "# --- A5 Self-reported Health History ---\n",
    "a5_cols = [\n",
    "    \"CVHATT\", \"HATTMULT\", \"CVAFIB\", \"CVANGIO\", \"CVBYPASS\", \"CVPACDEF\", \"CVPACE\",\n",
    "    \"CVCHF\", \"CVANGINA\", \"CVHVALVE\", \"CVOTHR\",\n",
    "    \"CBSTROKE\", \"STROKMUL\", \"CBTIA\", \"TIAMULT\",\n",
    "    \"DIABETES\", \"DIABTYPE\", \"HYPERTEN\", \"HYPERCHO\",\n",
    "    \"PD\", \"SEIZURES\", \"TBI\",\n",
    "    \"APNEA\", \"INSOMN\", \"DEP2YRS\", \"PTSD\", \"BIPOLAR\", \"ANXIETY\",\n",
    "    \"TOBAC30\", \"TOBAC100\", \"SMOKYRS\", \"PACKSPER\", \"QUITSMOK\",\n",
    "    \"ALCOCCAS\", \"ALCFREQ\", \"ABUSOTHR\",\n",
    "    \"NACCBMI\", 'HEIGHT', 'WEIGHT','THYROID','B12DEF','ARTHRIT','INCONTU'\n",
    "]\n",
    "\n",
    "# --- A3 Family History (optional/borderline) ---\n",
    "a3_cols = [\"NACCFAM\", \"NACCMOM\", \"NACCDAD\"]\n",
    "\n",
    "# Combine all columns\n",
    "selected_cols = a1_cols + a5_cols + a3_cols\n",
    "\n",
    "#define target column\n",
    "target_col=\"DEMENTED\"\n",
    "\n",
    "# Extract only those columns\n",
    "df_sel = df[selected_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba29c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_missing_age(x):\n",
    "    return np.nan if x in [888, 999, 995, 996, 997] else x\n",
    "\n",
    "def clean_educ(x):\n",
    "    return np.nan if x == 99 else x\n",
    "\n",
    "def a5_to_flag(s):\n",
    "    \"\"\"\n",
    "    A5 coding: \n",
    "    0 = No, 1 = Recent/Active, 2 = Remote/Inactive,\n",
    "    9 = Unknown, -4 = Not available\n",
    "    Convert (1) -> 1,(2) -> 2, (0) -> 0, unknown -> NaN\n",
    "    \"\"\"\n",
    "    return s.replace({1:1, 2:2, 0:0, 9:np.nan, -4:np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a6ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final dataframe\n",
    "df_final = pd.DataFrame(index=df_sel.index)\n",
    "\n",
    "# --- AGE ---\n",
    "df_final[\"AGE\"] = df_sel[\"NACCAGE\"].apply(clean_missing_age)\n",
    "\n",
    "# --- BASIC DEMO ---\n",
    "df_final[\"SEX\"] = df_sel[\"SEX\"]\n",
    "df_final[\"EDUC_YEARS\"] = df_sel[\"EDUC\"].apply(clean_educ)\n",
    "df_final[\"HANDED\"] = df_sel[\"HANDED\"]\n",
    "df_final[\"INDEPEND\"] = df_sel[\"INDEPEND\"]\n",
    "df_final[\"NACCLIVS\"] = df_sel[\"NACCLIVS\"]\n",
    "\n",
    "# --- LANGUAGE ---\n",
    "df_final[\"PRIMLANG\"] = df_sel[\"PRIMLANG\"]\n",
    "df_final[\"IS_NON_ENGLISH_HOME\"] = (df_sel[\"PRIMLANG\"] != 1).astype(int)\n",
    "\n",
    "# --- MARITAL (One-hot) ---\n",
    "df_final = pd.concat([df_final,\n",
    "                      pd.get_dummies(df_sel[\"MARISTAT\"], prefix=\"MARITAL\", dtype=int)],\n",
    "                     axis=1)\n",
    "\n",
    "# --- RESIDENCE (One-hot) ---\n",
    "df_final = pd.concat([df_final,\n",
    "                      pd.get_dummies(df_sel[\"RESIDENC\"], prefix=\"RESIDENCE\", dtype=int)],\n",
    "                     axis=1)\n",
    "\n",
    "# --- RACE ---\n",
    "df_final[\"RACE\"] = df_sel[\"RACE\"]\n",
    "df_final[\"IS_MULTIRACIAL\"] = (\n",
    "    df_sel[\"RACESEC\"].isin([1,2,3,4,5,50]) | \n",
    "    df_sel[\"RACETER\"].isin([1,2,3,4,5,50])\n",
    ").astype(int)\n",
    "df_final[\"RACE_OTHER\"] = (df_sel[\"RACE\"] == 50).astype(int)\n",
    "\n",
    "# One-hot for primary race\n",
    "df_final = pd.concat([df_final,\n",
    "                      pd.get_dummies(df_sel[\"RACE\"], prefix=\"RACE\", dtype=int)],\n",
    "                     axis=1)\n",
    "\n",
    "\n",
    "# A5 VARIABLES → BINARY FLAGS\n",
    "\n",
    "for col in a5_cols:\n",
    "    \n",
    "    if col == \"DIABTYPE\":\n",
    "        # keep DIABTYPE as numeric category, optional\n",
    "        df_final[\"DIABTYPE\"] = df_sel[\"DIABTYPE\"].replace({9:np.nan, -4:np.nan})\n",
    "    else:\n",
    "        df_final[col + \"_FLAG\"] = a5_to_flag(df_sel[col])\n",
    "\n",
    "# Smoking extras\n",
    "df_final[\"SMOKED_100PLUS\"] = df_sel[\"TOBAC100\"].replace({0:0, 1:1, 9:np.nan, -4:np.nan})\n",
    "\n",
    "df_final[\"SMOKED_LAST_30D\"] = df_sel[\"TOBAC30\"].replace({0:0,1:1, 9:np.nan, -4:np.nan})\n",
    "\n",
    "# BMI\n",
    "df_final[\"BMI\"] = df_sel[\"NACCBMI\"].replace({888.8:np.nan,-4:np.nan})\n",
    "\n",
    "# Fill missing BMI values by calculating BMI for rows where HEIGHT and WEIGHT exist.\n",
    "df_sel[\"HEIGHT\"] = df_sel[\"HEIGHT\"].replace({88.8:np.nan,-4:np.nan})\n",
    "df_sel[\"WEIGHT\"] = df_sel[\"WEIGHT\"].replace({888.0:np.nan,-4:np.nan})\n",
    "\n",
    "## BMI = (weight in lbs × 703) / (height in inches)^2\n",
    "df_final.loc[\n",
    "    df_final[\"BMI\"].isna() &\n",
    "    df_sel[\"HEIGHT\"].notna() &\n",
    "    df_sel[\"WEIGHT\"].notna(),\n",
    "    \"BMI\"\n",
    "] =  (df_sel[\"WEIGHT\"] * 703) / (df_sel[\"HEIGHT\"] ** 2)\n",
    "\n",
    "# A3 FAMILY HISTORY — OPTIONAL BUT INCLUDED\n",
    "\n",
    "for col in a3_cols:\n",
    "    df_final[col + \"_FLAG\"] = df_sel[col].replace({0:0,1:1,9:np.nan,-4:np.nan})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31aca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[target_col]\n",
    "X=df_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca51ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)\n",
    "\n",
    "df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a0e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df[\"NACCID\"].nunique()\n",
    "duplicates = (df[\"NACCID\"].value_counts() > 1).sum()\n",
    "\n",
    "print(\"Total unique participants:\", total)\n",
    "print(\"Participants with >1 visit:\", duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bda051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get participant IDs\n",
    "\n",
    "groups = df.loc[df.index, \"NACCID\"].reset_index(drop=True)\n",
    "\n",
    "# 2. First split: Train vs Temp (Val+Test)\n",
    "\n",
    "gss1 = GroupShuffleSplit(n_splits=1, test_size=0.30, random_state=42)\n",
    "\n",
    "train_idx, temp_idx = next(gss1.split(X, y, groups=groups))\n",
    "\n",
    "X_train = X.iloc[train_idx]\n",
    "y_train = y.iloc[train_idx]\n",
    "\n",
    "X_temp  = X.iloc[temp_idx]\n",
    "y_temp  = y.iloc[temp_idx]\n",
    "groups_temp = groups.iloc[temp_idx]\n",
    "\n",
    "\n",
    "# 3. Second split: Validation vs Test\n",
    "\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.50, random_state=42)\n",
    "\n",
    "val_idx, test_idx = next(gss2.split(X_temp, y_temp, groups=groups_temp))\n",
    "\n",
    "X_val  = X_temp.iloc[val_idx]\n",
    "y_val  = y_temp.iloc[val_idx]\n",
    "\n",
    "X_test = X_temp.iloc[test_idx]\n",
    "y_test = y_temp.iloc[test_idx]\n",
    "\n",
    "# 4. Print results\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation:\", X_val.shape, y_val.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)\n",
    "\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(\"Train:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"Val:\\n\",   y_val.value_counts(normalize=True))\n",
    "print(\"Test:\\n\",  y_test.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nUnique participants:\")\n",
    "print(\"Train:\", len(groups.iloc[train_idx].unique()))\n",
    "print(\"Val:\",   len(groups_temp.iloc[val_idx].unique()))\n",
    "print(\"Test:\",  len(groups_temp.iloc[test_idx].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfcc5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model, X_val, y_val, X_test, y_test):\n",
    "    # VALIDATION SET Evaluation\n",
    "    val_proba = model.predict_proba(X_val)[:, 1]\n",
    "    val_pred = (val_proba > 0.5).astype(int)\n",
    "\n",
    "    val_auc = roc_auc_score(y_val, val_proba)\n",
    "    val_acc = accuracy_score(y_val, val_pred)\n",
    "\n",
    "    # TEST SET Evaluation\n",
    "    test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    test_pred = (test_proba > 0.5).astype(int)\n",
    "\n",
    "    test_auc = roc_auc_score(y_test, test_proba)\n",
    "    test_acc = accuracy_score(y_test, test_pred)\n",
    "\n",
    "    print(\"====================================\")\n",
    "    print(\"   RANDOM FOREST FINAL EVALUATION    \")\n",
    "    print(\"====================================\")\n",
    "    print(f\"Validation AUC: {val_auc:.4f}\")\n",
    "    print(f\"Validation ACC: {val_acc:.4f}\")\n",
    "    print(\"------------------------------------\")\n",
    "    print(f\"Test AUC:       {test_auc:.4f}\")\n",
    "    print(f\"Test ACC:       {test_acc:.4f}\")\n",
    "    print(\"====================================\")\n",
    "\n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db11e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''rf_grid = {\n",
    "    \"n_estimators\": [200, 300],\n",
    "    \"max_depth\": [15, 20, 25],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"class_weight\": [\"balanced\"]\n",
    "    }\n",
    "\n",
    "rf_model = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=rf_grid,\n",
    "    cv=3,\n",
    "    scoring=\"roc_auc\",\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest RF Params:\", grid_rf.best_params_)\n",
    "print(\"Best RF CV AUC:\", grid_rf.best_score_)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235af644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. BEST PARAMS FROM GRID SEARCH\n",
    "\n",
    "best_rf_params = {\n",
    "    'class_weight': 'balanced',\n",
    "    'max_depth': 15,\n",
    "    'min_samples_leaf': 4,\n",
    "    'min_samples_split': 10,\n",
    "    'n_estimators': 300\n",
    "}\n",
    "\n",
    "\n",
    "# 2. TRAIN FINAL MODEL ON TRAINING SET\n",
    "\n",
    "rf_final = RandomForestClassifier(\n",
    "    **best_rf_params,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_final.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a3e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate Random Forest Model \n",
    "model_evaluation(rf_final, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11518ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_of_rf=pd.DataFrame({\n",
    "    'featura' : X.columns,\n",
    "    'importance' : rf_final.feature_importances_\n",
    "}).sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0005ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_of_rf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0843eaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. XGBOOST PARAMETER SEARCH SPACE (Optimized for tabular data)\n",
    "'''\n",
    "\n",
    "xgb_param_dist = {\n",
    "    \"n_estimators\": [300, 400, 500],\n",
    "    \"max_depth\": [3, 4, 5, 6],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.1],\n",
    "    \"subsample\": [0.6, 0.7, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.7, 0.8, 1.0],\n",
    "    \"gamma\": [0, 1, 5],\n",
    "    \"min_child_weight\": [1, 3, 5, 7],\n",
    "    \"reg_alpha\": [0, 0.01, 0.1],\n",
    "    \"reg_lambda\": [1, 1.5, 2.0]\n",
    "}\n",
    "\n",
    "\n",
    "# 2. Create base XGB model\n",
    "\n",
    "xgb_base = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    tree_method=\"hist\",     \n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# 3. Randomized Search \n",
    "\n",
    "rand_xgb = RandomizedSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_distributions=xgb_param_dist,\n",
    "    n_iter=40,                 \n",
    "    scoring=\"roc_auc\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "# 4. Fit on the TRAIN set\n",
    "\n",
    "\n",
    "rand_xgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest XGB Params:\", rand_xgb.best_params_)\n",
    "print(\"Best XGB CV AUC:\", rand_xgb.best_score_)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d5530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract best parameters\n",
    "best_xgb_params = { 'subsample': 0.6, \n",
    "                    'reg_lambda': 2.0, \n",
    "                    'reg_alpha': 0.01, \n",
    "                    'n_estimators': 300, \n",
    "                    'min_child_weight': 1, \n",
    "                    'max_depth': 5,\n",
    "                    'learning_rate': 0.03, \n",
    "                    'gamma': 0, \n",
    "                    'colsample_bytree': 1.0\n",
    "                    }\n",
    "\n",
    "# 2. Re-train final XGB model on full TRAIN set\n",
    "\n",
    "xgb_final = XGBClassifier(\n",
    "    **best_xgb_params,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_final.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate XGB Model\n",
    "model_evaluation(xgb_final, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f65a542",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_of_xgb=pd.DataFrame({\n",
    "    'featura' : X.columns,\n",
    "    'importance' : xgb_final.feature_importances_\n",
    "}).sort_values('importance',ascending=False)\n",
    "\n",
    "importance_df_of_xgb.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e251f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Define Search Space for CatBoost\n",
    "\n",
    "cat_param_dist = {\n",
    "    \"iterations\": [300, 500, 700, 900],\n",
    "    \"depth\": [4, 5, 6, 7, 8],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.07],\n",
    "    \"l2_leaf_reg\": [1, 3, 5, 7, 9],\n",
    "    \"subsample\": [0.6, 0.7, 0.8, 1.0],\n",
    "    \"border_count\": [32, 64, 128, 254]\n",
    "}\n",
    "\n",
    "\n",
    "# 2. Base CatBoost Model\n",
    "\n",
    "cat_base = CatBoostClassifier(\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"AUC\",\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    "    \n",
    ")\n",
    "\n",
    "# 3. Random Search\n",
    "\n",
    "cat_search = RandomizedSearchCV(\n",
    "    estimator=cat_base,\n",
    "    param_distributions=cat_param_dist,\n",
    "    n_iter=40,            \n",
    "    scoring=\"roc_auc\",\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 4. Fit\n",
    "cat_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best CatBoost Params:\", cat_search.best_params_)\n",
    "print(\"Best CV AUC:\", cat_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5073e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cat_params={\n",
    "                'subsample': 1.0, \n",
    "                 'learning_rate': 0.03, \n",
    "                 'l2_leaf_reg': 9, \n",
    "                 'iterations': 500, \n",
    "                 'depth': 8, \n",
    "                 'border_count': 254}\n",
    "    \n",
    "\n",
    "# 1. CATBOOST FINAL MODEL TRAINING\n",
    "\n",
    "cat_final = CatBoostClassifier(\n",
    "   **best_cat_params,\n",
    "    eval_metric='AUC',\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    "    thread_count = -1\n",
    "\n",
    ")\n",
    "\n",
    "cat_final.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62271f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate CatBoost Model\n",
    "model_evaluation(cat_final, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c05f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. LightGBM Search Space\n",
    "\n",
    "lgb_param_dist = {\n",
    "    \"n_estimators\": [300, 500, 800],\n",
    "    \"max_depth\": [-1, 4, 6, 8, 10],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.1],\n",
    "    \"num_leaves\": [20, 30, 40, 50, 60],\n",
    "    \"subsample\": [0.6, 0.7, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.7, 0.8, 1.0],\n",
    "    \"reg_alpha\": [0, 0.01, 0.1],\n",
    "    \"reg_lambda\": [0.1, 0.3, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "\n",
    "# 2. Base Model\n",
    "\n",
    "lgb_base = LGBMClassifier(\n",
    "    objective=\"binary\",\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# 3. Randomized Search\n",
    "\n",
    "lgb_search = RandomizedSearchCV(\n",
    "    estimator=lgb_base,\n",
    "    param_distributions=lgb_param_dist,\n",
    "    n_iter=40,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# 4. Fit\n",
    "\n",
    "lgb_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best LGBM Params:\", lgb_search.best_params_)\n",
    "print(\"Best LGBM CV AUC:\", lgb_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e53813",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. LIGHTGBM (Fast, strong boosting)\n",
    "\n",
    "best_lgb_params = {'subsample': 1.0, \n",
    "                   'reg_lambda': 0.5, \n",
    "                   'reg_alpha': 0,\n",
    "                    'num_leaves': 40,\n",
    "                    'n_estimators': 800, \n",
    "                    'max_depth': 8, \n",
    "                    'learning_rate': 0.01, \n",
    "                    'colsample_bytree': 0.6}\n",
    "\n",
    "lgb_final = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=-1,\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgb_final.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad82e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate LightGBM Model\n",
    "model_evaluation(lgb_final, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d244a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get PREDICTIONS for VALIDATION SET\n",
    "\n",
    "rf_val_proba  = rf_final.predict_proba(X_val)[:, 1]\n",
    "xgb_val_proba = xgb_final.predict_proba(X_val)[:, 1]\n",
    "lgb_val_proba = lgb_final.predict_proba(X_val)[:, 1]\n",
    "cat_val_proba = cat_final.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Build meta-feature matrix\n",
    "stack_val_X = np.column_stack([\n",
    "    rf_val_proba,\n",
    "    xgb_val_proba,\n",
    "    lgb_val_proba,\n",
    "    cat_val_proba\n",
    "])\n",
    "\n",
    "# 2. Train META-MODEL (Linear Regression)\n",
    "\n",
    "\n",
    "meta_model = LinearRegression()\n",
    "meta_model.fit(stack_val_X, y_val)\n",
    "\n",
    "print(\"\\nMeta Model Weights:\", meta_model.coef_)\n",
    "print(\"Meta Model Bias:\", meta_model.intercept_)\n",
    "\n",
    "\n",
    "# 3. Evaluate stacking on VALIDATION SET\n",
    "\n",
    "val_meta_pred = meta_model.predict(stack_val_X)\n",
    "val_auc = roc_auc_score(y_val, val_meta_pred)\n",
    "\n",
    "print(\"\\n============================================\")\n",
    "print(\"Validation AUC (4-Model Stacking):\", round(val_auc, 4))\n",
    "print(\"============================================\")\n",
    "\n",
    "\n",
    "# 4. Get predictions on TEST SET\n",
    "\n",
    "rf_test_proba  = rf_final.predict_proba(X_test)[:, 1]\n",
    "xgb_test_proba = xgb_final.predict_proba(X_test)[:, 1]\n",
    "lgb_test_proba = lgb_final.predict_proba(X_test)[:, 1]\n",
    "cat_test_proba = cat_final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Build test meta-feature set\n",
    "stack_test_X = np.column_stack([\n",
    "    rf_test_proba,\n",
    "    xgb_test_proba,\n",
    "    lgb_test_proba,\n",
    "    cat_test_proba\n",
    "])\n",
    "\n",
    "# 5. Final TEST SET prediction\n",
    "\n",
    "test_meta_pred = meta_model.predict(stack_test_X)\n",
    "test_auc = roc_auc_score(y_test, test_meta_pred)\n",
    "\n",
    "print(\"\\n============================================\")\n",
    "print(\"Test AUC (4-Model Stacking):\", round(test_auc, 4))\n",
    "print(\"============================================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
